layout:     post
title:      基于0-1乘性噪声的图像恢复
subtitle:   图像局部性原理应用
date:       2020-06-04
author:     Stitch
header-img: img/post-bg-debug.png
catalog: true
tags:

    - Algorithm
    - Machine Learning

# 基于0-1乘性噪声的图像恢复

#### 问题引入

图像是一种非常常见的信息载体，但是在图像的获取、传输、存储的过程中可能由于各种原因使得图像受到噪声的影响。
如何去除噪声的影响，恢复图像原本的信息是计算机视觉中的重要研究问题。

常见的图像恢复算法有基于空间域的中值滤波、基于小波域的小波去噪、基于偏微分方程的非线性扩散滤波等，在本次实验中，我们要对图像添加噪声，并对添加噪声的图像进行基于模型的去噪。

#### 算法描述

##### 添加噪声

受损图像（$X$）是由原始图像（<img src="https://raw.githubusercontent.com/StitchWuhula/StitchWuhula.github.io/master/img/post_img/2020_06_04/mylatex20200604_094239.svg" style="zoom:70%;" />）添加了不同的噪声遮罩（<img src="https://raw.githubusercontent.com/StitchWuhula/StitchWuhula.github.io/master/img/post_img/2020_06_04/mylatex20200604_094427.svg" style="zoom:70%;" />）得到的（<img src="https://raw.githubusercontent.com/StitchWuhula/StitchWuhula.github.io/master/img/post_img/2020_06_04/mylatex20200604_094509.svg" style="zoom:70%;" />），其中 <img src="https://raw.githubusercontent.com/StitchWuhula/StitchWuhula.github.io/master/img/post_img/2020_06_04/mylatex20200604_094544.svg" style="zoom:70%;" /> 表示逐元素相乘。在本实验中，噪声遮罩仅包含{0，1}值。对原图的噪声遮罩每行分别用 0.8/0.4/0.6 的噪声比率产生的，即噪声遮罩每个通道每行 80%/40%/60% 的像素值为0，其他为1。

##### 图像去噪

图像的像素点在空间上具有局部相似性的特征，空间上临近的像素点在通道值上的变化往往是平滑且包含联系的。在本实验中，我们注意到噪声遮罩仅包含{0，1}值，且以乘性方式添加到原图像；换句话说，噪声图像由一部分无损的像素和一部分全损的像素构成，我们可以针对每个区域建立一个模型来拟合临近区域内的无损像素值，最后用模型来预测区域内全损像素的值。

<img src="https://raw.githubusercontent.com/StitchWuhula/StitchWuhula.github.io/master/img/post_img/2020_06_04/mylatex20200604_093928.svg" style="zoom:70%;" />

具体实现中，我们首先使用一个固定大小的滑动窗口在图像上以固定步长移动，然后用一个三维线性模型来拟合每个矩阵中位置、通道数和通道值的关系。

因为每个模型只拟合滑动窗口内的像素位置和像素值的关系，因此我们考虑对像素位置进行变换。这样做的目的是强化像素的局部相似性特征，以期提高模型对噪声位置像素值的预测能力。假定我们对图像中一个 size * size 大小的像素矩阵进行去噪，<img src="https://raw.githubusercontent.com/StitchWuhula/StitchWuhula.github.io/master/img/post_img/2020_06_04/mylatex20200604_095128.svg" style="zoom:70%;" /> 为矩阵像素坐标，<img src="https://raw.githubusercontent.com/StitchWuhula/StitchWuhula.github.io/master/img/post_img/2020_06_04/mylatex20200604_095245.svg" style="zoom:70%;" />为矩阵中心坐标，则坐标转换方程如下：

<img src="https://raw.githubusercontent.com/StitchWuhula/StitchWuhula.github.io/master/img/post_img/2020_06_04/mylatex20200604_094055.svg" style="zoom:80%;" />

我们实际要回归的就是点心距与像素通道值的关系。

这样的坐标变换方程仍然是基于局部性原理。就我们的常识而言，局部相似性与方向无关，中心点的上下、左右位置是完全对称、等价的，特别是在若干个像素大小的尺度上。变换方程中的尺度放缩、平方运算就体现了这样的思路。

#### 代码实现

##### 添加噪声

这部分的实现较为简单，代码和说明在这里直接呈现。

```python
def noise_mask_image(img, noise_ratio):
    """
    :param img: 图像矩阵，一般为 np.ndarray
    :param noise_ratio: 噪声比率，可能值是0.4/0.6/0.8
    :return: noise_img 受损图片, 图像矩阵值 0-1 之间，数据类型为 np.array, 
             数据类型对象 (dtype): np.double, 图像形状:(height,width,channel),通道(channel) 顺序为RGB
    """
   
    noise_img = None
    height, width, channel = img.shape
    # 生成随机噪声
    raw_noise = np.random.rand(height, width, channel)
    # noise_ratio比例的噪声值变为0，其余为1
    noise = np.where(raw_noise < noise_ratio, 0, 1)
    # 添加噪声
    noise_img = img*noise

    return noise_img
```

##### 图像去噪

图像去噪部分主要由四个函数完成，下面进行简要说明。具体代码详见附录。

- `sampleArea()`:

  参数：image（噪声图像矩阵，np.ndarray），滑动窗口左上横坐标（sx，int），滑动窗口左上纵坐标（sy，int），图像通道数（channels，int），滑动窗口大小（size，int）

  返回值：无损像素的特征构成的列表（data，List[tuple]），每个特征以tuple表示，包括（变换后的横坐标，变换后的纵坐标，通道坐标，通道值）

  说明：该函数遍历滑动窗口内像素获取无损像素特征，这些特征作为待拟合数据

- `restoreArea()`

  参数：image（部分修复图像矩阵，np.ndarray），滑动窗口左上横坐标（sx，int），滑动窗口左上纵坐标（sy，int），图像通道数（channels，int），滑动窗口大小（size，int），拟合参数矩阵（w，np.ndarray）

  返回值：部分修复图像矩阵（res_image，np.ndarray）

  说明：该函数遍历滑动窗口内像素修复其中的噪声点

- `fit()`

  参数：无损像素的特征构成的列表（data，List[tuple]），来自`sampleArea()`函数

  返回值：拟合参数矩阵（w，np.ndarray）

  说明：该函数采用最小二回归和梯度下降法拟合数据。设定步长为 0.005，共迭代 100 轮。

- `predict()`

  参数：拟合参数矩阵（w，np.ndarray），待预测通道特征（data，tuple），特征包括（变换后的横坐标，变换后的纵坐标，通道坐标）	

  返回值：预测的通道值（val，float（[0，1]））

  说明：该函数用于预测单个通道值

#### 实验测试

介绍完算法和代码实现，我们可以看到矩阵块大小 size 是项目的关键超参数。

下面我们就对不同的 size 进行了测试，测试结果如下

| SIZE(像素) | 恢复用时(秒) | 评估误差 | SSIM相似度 | Cosine相似度 |
| ---------- | ------------ | -------- | ---------- | ------------ |
| 3          | 179.76       | 51.305   | 0.624      | 0.987        |
| 4          | 177.38       | 49.931   | 0.660      | 0.988        |
| 5          | 178.22       | 51.708   | 0.655      | 0.987        |

<img src="https://raw.githubusercontent.com/StitchWuhula/StitchWuhula.github.io/master/img/post_img/2020_06_04/mona_lisa.png" style="zoom:40%;padding-left:200px"/>                    <img src="https://raw.githubusercontent.com/StitchWuhula/StitchWuhula.github.io/master/img/post_img/2020_06_04/noise_mona_lisa.png" style="zoom:40%;" />     

<center>图1 原图 &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;图2 噪声图像</center>   

<img src="https://raw.githubusercontent.com/StitchWuhula/StitchWuhula.github.io/master/img/post_img/2020_06_04/res_mona_lisa_3.png" alt="图片" style="zoom:40%;"/>      <img src="https://raw.githubusercontent.com/StitchWuhula/StitchWuhula.github.io/master/img/post_img/2020_06_04/res_mona_lisa_4.png" alt="图片" style="zoom:40%;"/>     <img src="https://raw.githubusercontent.com/StitchWuhula/StitchWuhula.github.io/master/img/post_img/2020_06_04/res_mona_lisa_5.png" alt="图片" style="zoom:40%;" />

<center>图3 size=3的修复图&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;图4 size=4的修复图&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;图5 size=5的修复图</center>

根据测试结果，不同的 size 值对图像恢复的时间几乎没有影响，而在评估误差、SSIM相似度和 Cosine相似度上，size = 4的复原效果都要好于其它两个参数，但是和 size = 5的复原结果差距并不大。

肉眼的观测结果也佐证了上述数值测试结果。可以看到上面三张复原图都较为完整地还原了原图的色彩和图案，就三者比较而言，图3 最为为细腻，细节上和原图接近，但是充斥了大量明显的蓝色或者浅蓝色噪点；图4 ，图5 无可见的明显噪点，但是图5 的颗粒感很显著，仿佛是在原图上打了细小的马赛克；图2则 较好地在清晰的和完整度之间保持了平衡，具有最佳的视觉效果。

#### 总结

本项目主要实现了一种基于0-1乘性噪声的图像恢复方法，核心是利用了图像的空间局部相似性，通过区域内的无损像素来预测噪点处的像素值。

该方法仍然存在若干可优化之处：

- 时间：目前恢复一张图片所需时间在180s左右。可以考虑通过 GPU的 CUDA 对矩阵运算加速。
- 模型：这里为了方便采用了线性模型对像素值进行拟合，更加复杂的拟合模型或许能帮助提高效果

不过需要指出的是，这种方法仅对这种特殊噪声情况有效，并且对原始图像的色彩分布也有一定的要求。

#### 附录

```python
import numpy as np

def restore_image(noise_img, size=4):
    """
    :param noise_img: 一个受损的图像
    :param size: 输入区域半径，长宽是以 size*size 方形区域获取区域, 默认是 4
    :return: res_img 恢复后的图片，图像矩阵值 0-1 之间，数据类型为 np.array,
            数据类型对象 (dtype): np.double, 图像形状:(height,width,channel), 通道(channel) 顺序为RGB
    """
    res_img = np.copy(noise_img)
    noise_mask = get_noise_mask(noise_img)

    height, width, channels = res_img.shape[0], res_img.shape[1], res_img.shape[2]
    size = 4
    step = size - 1
    for i in range(0, height-size, step):
        for j in range(0, width-size, step):
            data = convSample(res_img, i, j, channels, size)
            w = fit(data)
            res_image = convRestore(res_img, i, j, channels, size, w)

    return res_img

def sampleArea(image, sx, sy, channels, size):
    midx = sx+size//2
    midy = sy+size//2
    data = []
    for x in range(sx, sx+size):
        for y in range(sy, sy+size):              
            nx = ((x-midx)/size)**2/2
            ny = ((y-midy)/size)**2/2
            for k in range(channels):
                if image[x][y][k] == 0: continue
                data.append((nx, ny, k, image[x][y][k]))
    return data

def restoreArea(image, sx, sy, channels, size, w):
    midx = sx+size//2
    midy = sy+size//2
    for x in range(sx, sx+size):
        for y in range(sy, sy+size):            
            nx = ((x-midx)/size)**2/2
            ny = ((y-midy)/size)**2/2
            for k in range(channels):
                if image[x][y][k] != 0: continue
                image[x][y][k] = predict(w, (nx, ny, k))
    return image

def fit(data):
    w = np.zeros(4)
    x = np.zeros(4)
    for i in range(100):
        for a,b,c,val in data:
            x[0],x[1],x[2],x[3] = 1,a,b,c
            y = val
            coef = 0.01*(y-w.dot(x))
            w += coef*x
    return w

def predict(w, data):
    x = np.zeros(4)
    x[0],x[1],x[2],x[3] = 1, data[0], data[1], data[2]
    val = w.dot(x)
    val = min(max(0, val),1)
    return val
```

